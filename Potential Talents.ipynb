{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to get multiple outputs in the same cell\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity='all'\n",
    "\n",
    "#Code to ignore all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings(action='ignore',category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019 C.T. Bauer College of Business Graduate (...</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Native English Teacher at EPIK (English Progra...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>People Development Coordinator at Ryan</td>\n",
       "      <td>Denton, Texas</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>İzmir, Türkiye</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                          job_title  \\\n",
       "0   1  2019 C.T. Bauer College of Business Graduate (...   \n",
       "1   2  Native English Teacher at EPIK (English Progra...   \n",
       "2   3              Aspiring Human Resources Professional   \n",
       "3   4             People Development Coordinator at Ryan   \n",
       "4   5    Advisory Board Member at Celal Bayar University   \n",
       "\n",
       "                              location connection  fit  \n",
       "0                       Houston, Texas         85  NaN  \n",
       "1                               Kanada      500+   NaN  \n",
       "2  Raleigh-Durham, North Carolina Area         44  NaN  \n",
       "3                        Denton, Texas      500+   NaN  \n",
       "4                       İzmir, Türkiye      500+   NaN  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(r\"C:\\Users\\97158\\Desktop\\Apziva\\Project 3- Potential Talents\\potential-talents - Aspiring human resources - seeking human resources.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.drop('fit', axis=1)\n",
    "y=data['fit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing relevant libraries\n",
    "\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk. stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_title=list(X['job_title'])\n",
    "len(job_title)\n",
    "job_title[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019 c.t. bauer college of business graduate (magna cum laude) and aspiring human resources professional'"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of first job_title:  104\n"
     ]
    }
   ],
   "source": [
    "#Making all text lower case\n",
    "\n",
    "job_title_LowC=[word.lower() for word in job_title]\n",
    "job_title_LowC[0]\n",
    "print(\"Length of first job_title: \",len(job_title_LowC[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2019',\n",
       " 'c.t',\n",
       " '.',\n",
       " 'bauer',\n",
       " 'college',\n",
       " 'of',\n",
       " 'business',\n",
       " 'graduate',\n",
       " '(',\n",
       " 'magna',\n",
       " 'cum',\n",
       " 'laude',\n",
       " ')',\n",
       " 'and',\n",
       " 'aspiring',\n",
       " 'human',\n",
       " 'resources',\n",
       " 'professional']"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of first job_title:  18\n"
     ]
    }
   ],
   "source": [
    "# tokenize doc in list(job_title)\n",
    "\n",
    "tokens= [word_tokenize(word) for word in job_title_LowC]\n",
    "tokens[0]\n",
    "print(\"Length of first job_title: \",len(tokens[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we']"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing stop words in the document\n",
    "\n",
    "sw=stopwords.words('english')\n",
    "sw[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2019',\n",
       " 'c.t',\n",
       " '.',\n",
       " 'bauer',\n",
       " 'college',\n",
       " 'business',\n",
       " 'graduate',\n",
       " '(',\n",
       " 'magna',\n",
       " 'cum',\n",
       " 'laude',\n",
       " ')',\n",
       " 'aspiring',\n",
       " 'human',\n",
       " 'resources',\n",
       " 'professional']"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of first job_title:  16\n"
     ]
    }
   ],
   "source": [
    "# removing stopwords from each doc in list(job_title)\n",
    "# doc in list\n",
    "# words in doc\n",
    "\n",
    "tokens= [[word for word in doc if word not in sw] for doc in tokens]\n",
    "tokens[0]\n",
    "print(\"Length of first job_title: \",len(tokens[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Punctuation\n",
    "\n",
    "tokenizer=RegexpTokenizer(r'\\w+')\n",
    "tokens=[[\"\".join(tokenizer.tokenize(word)) for word in doc if len(tokenizer.tokenize(word))>0] for doc in tokens]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2019',\n",
       " 'ct',\n",
       " 'bauer',\n",
       " 'college',\n",
       " 'business',\n",
       " 'graduate',\n",
       " 'magna',\n",
       " 'cum',\n",
       " 'laude',\n",
       " 'aspiring',\n",
       " 'human',\n",
       " 'resources',\n",
       " 'professional']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of first job_title:  13\n"
     ]
    }
   ],
   "source": [
    "tokens[0]\n",
    "print(\"Length of first job_title: \",len(tokens[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming\n",
    "\n",
    "porter=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2019',\n",
       " 'ct',\n",
       " 'bauer',\n",
       " 'colleg',\n",
       " 'busi',\n",
       " 'graduat',\n",
       " 'magna',\n",
       " 'cum',\n",
       " 'laud',\n",
       " 'aspir',\n",
       " 'human',\n",
       " 'resourc',\n",
       " 'profession']"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of first job_title:  13\n"
     ]
    }
   ],
   "source": [
    "# Finding root words across documents\n",
    "# tokens in docs\n",
    "# words in docs\n",
    "\n",
    "\n",
    "tokens= [[porter.stem(word) for word in doc] for doc in tokens]\n",
    "\n",
    "tokens[0]\n",
    "print(\"Length of first job_title: \",len(tokens[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019 ct bauer colleg busi graduat magna cum laud aspir human resourc profession'"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of all job_titles:  104\n"
     ]
    }
   ],
   "source": [
    "# Implementing Bag of words\n",
    "\n",
    "Clean_job_title=[\" \".join(word) for word in tokens]\n",
    "Clean_job_title[0]\n",
    "\n",
    "print(\"Length of all job_titles: \",len(Clean_job_title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104, 35)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "scipy.sparse._csr.csr_matrix"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "sklearn.feature_extraction.text.CountVectorizer"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect=CountVectorizer(binary=True, min_df=5)\n",
    "\n",
    "matrix=vect.fit_transform(Clean_job_title)\n",
    "\n",
    "matrix.shape  #Returns x and y where x is the total number of tekens and y is the count of binary tokens appearing it atleast 5 documents\n",
    "type(matrix)\n",
    "type(vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above x and y shape pertains to x being the total number of tokens and y being the count of binary tokens appearing it atleast 5 documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the number of unique words in the library\n",
    "len(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104, 35)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array(<104x35 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 427 stored elements in Compressed Sparse Row format>, dtype=object)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting Sparse Matrix into Array\n",
    "\n",
    "x_array=matrix\n",
    "g=np.squeeze(np.asarray(matrix))\n",
    "\n",
    "x_array.shape\n",
    "g.shape\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cos_sim=cosine_similarity(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.       , 0.       , 0.5547002, ..., 0.2773501, 0.       ,\n",
       "        0.       ],\n",
       "       [0.       , 1.       , 0.       , ..., 0.       , 0.       ,\n",
       "        0.       ],\n",
       "       [0.5547002, 0.       , 1.       , ..., 0.       , 0.       ,\n",
       "        0.       ],\n",
       "       ...,\n",
       "       [0.2773501, 0.       , 0.       , ..., 1.       , 0.       ,\n",
       "        0.       ],\n",
       "       [0.       , 0.       , 0.       , ..., 0.       , 0.       ,\n",
       "        0.       ],\n",
       "       [0.       , 0.       , 0.       , ..., 0.       , 0.       ,\n",
       "        0.       ]])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "cos_sim1=linear_kernel(matrix, matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13.,  0.,  4., ...,  1.,  0.,  0.],\n",
       "       [ 0.,  6.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 4.,  0.,  4., ...,  0.,  0.,  0.],\n",
       "       ...,\n",
       "       [ 1.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Recommendation Engine\n",
    "\n",
    "# def recommend(job_title, cosine_similarity=cos_sim):\n",
    "#     index = Clean_job_title.index(job_title)\n",
    "#     sim_score = list(enumerate(cos_sim[index]))\n",
    "#     sim_score = sorted(sim_score, key= lambda x: x[1], reverse=True)[1:11] #position 0 is the movie itself, thus exclude\n",
    "#     recommend_index = [i[0] for i in sim_score]\n",
    "#     rec_movie = data['job_title'].iloc[recommend_index]\n",
    "#     rec_score = [round(i[1],4) for i in sim_score]\n",
    "#     rec_table = pd.DataFrame(list(zip(rec_movie,rec_score)), columns=['Recommend Candidate','Similarity(0-1)'])\n",
    "#     return rec_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Recommendation Engine\n",
    "\n",
    "# from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# def find_similar(tfidf_matrix, index, top_n = 5):\n",
    "#     cosine_similarities = linear_kernel(tfidf_matrix[index:index+1], tfidf_matrix).flatten()\n",
    "#     related_docs_indices = [i for i in cosine_similarities.argsort()[::-1] if i != index]\n",
    "#     return [(index, cosine_similarities[index]) for index in related_docs_indices][0:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cos_sim(a,b):\n",
    "\n",
    "    return dot(a, b)/(norm(a)*norm(b)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to clean the text\n",
    "\n",
    "\n",
    "# Function to to make all text lowercase\n",
    "def make_lowercase(text):\n",
    "    lower=list(text)\n",
    "    lower= [doc.lower() for doc in text]\n",
    "    return lower\n",
    "\n",
    "#Removing numbers\n",
    "def remove_numbers(text):\n",
    "    remover=[[re.sub(r'\\d+','',word) for word in doc] for doc in text]\n",
    "    #remover=re.sub(r'\\d+','',text) # \\d+ removes numbers. re.sub finds and replaces that pattern in text. Takes 3 arguments \n",
    "    return remover\n",
    "\n",
    "#Removing punctuations\n",
    "regex=RegexpTokenizer(r'\\w+')\n",
    "def remove_punctuations(text):\n",
    "    removed_punct= [[\"\".join(regex.tokenize(word)) for word in doc if len(regex.tokenize(word))>0] for doc in text]  \n",
    "    return removed_punct\n",
    "\n",
    "#Removing Stop Words\n",
    "stop_words=stopwords.words('english')\n",
    "def remove_stopwords(text):\n",
    "    sw_remover=[[word for word in doc if word not in stop_words] for doc in text]\n",
    "    return sw_remover\n",
    "\n",
    "\n",
    "#Tokenizing texts\n",
    "def tokenize(text):\n",
    "    tokens=[word_tokenize(doc) for doc in text]\n",
    "    return tokens\n",
    "\n",
    "#Lemmatize Words\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "def root(text):\n",
    "    #flattened_text=[word for sublist in text for word in sublist]\n",
    "    #lemmatized_text=[lemmatizer.lemmatize(word) for word in flattened_text]\n",
    "    # text= [lemmatizer.lemmatize(word) for word_list in text for word in word_list]\n",
    "    lem_text= [[lemmatizer.lemmatize(word) for word in doc] for doc in text]\n",
    "    return lem_text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Compiling all the above def functions to preprocess all in one step\n",
    "\n",
    "def preprocess(text):\n",
    "\n",
    "    text=make_lowercase(text)\n",
    "    text=tokenize(text)\n",
    "    text=remove_stopwords(text)\n",
    "    text=remove_punctuations(text)\n",
    "    text=remove_numbers(text)\n",
    "    text=root(text)\n",
    "  \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['job_title']=preprocess(data['job_title'])\n",
    "data['location']=preprocess(data['location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[, ct, bauer, college, business, graduate, mag...</td>\n",
       "      <td>[houston, texas]</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[native, english, teacher, epik, english, prog...</td>\n",
       "      <td>[kanada]</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[aspiring, human, resource, professional]</td>\n",
       "      <td>[raleighdurham, north, carolina, area]</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[people, development, coordinator, ryan]</td>\n",
       "      <td>[denton, texas]</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[advisory, board, member, celal, bayar, univer...</td>\n",
       "      <td>[izmir, türkiye]</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                          job_title  \\\n",
       "0   1  [, ct, bauer, college, business, graduate, mag...   \n",
       "1   2  [native, english, teacher, epik, english, prog...   \n",
       "2   3          [aspiring, human, resource, professional]   \n",
       "3   4           [people, development, coordinator, ryan]   \n",
       "4   5  [advisory, board, member, celal, bayar, univer...   \n",
       "\n",
       "                                 location connection  fit  \n",
       "0                        [houston, texas]         85  NaN  \n",
       "1                                [kanada]      500+   NaN  \n",
       "2  [raleighdurham, north, carolina, area]         44  NaN  \n",
       "3                         [denton, texas]      500+   NaN  \n",
       "4                        [izmir, türkiye]      500+   NaN  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('human', 63),\n",
       " ('resource', 63),\n",
       " ('aspiring', 35),\n",
       " ('professional', 21),\n",
       " ('student', 16),\n",
       " ('seeking', 15),\n",
       " ('college', 14),\n",
       " ('generalist', 14),\n",
       " ('university', 12),\n",
       " ('specialist', 12)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_tokens=[word for t in data['job_title'] for word in t]\n",
    "counts=Counter(flat_tokens)\n",
    "\n",
    "counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data.job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec<vocab=67, vector_size=100, alpha=0.025>\n"
     ]
    }
   ],
   "source": [
    "# Training Skip Gram Model\n",
    "\n",
    "skipgram2=Word2Vec(x,vector_size=100,window=1,min_count=2,sg=1)\n",
    "\n",
    "#Window=3 means model will consider 1 word at a time while training\n",
    "#min_count=2 means that words that appear at least twice will be included in the vocab.\n",
    "\n",
    "print(skipgram2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText<vocab=67, vector_size=100, alpha=0.025>\n"
     ]
    }
   ],
   "source": [
    "# Training FastText Model\n",
    "\n",
    "fast_n= FastText(x, vector_size=100, window=2, min_count=2, min_n=1, max_n=2, sg=1)\n",
    "\n",
    "# A large window size allows the model to look at more context\n",
    "\n",
    "print(fast_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('marketing', 0.203652024269104),\n",
       " ('bauer', 0.1899968385696411),\n",
       " ('manager', 0.18948908150196075),\n",
       " ('hr', 0.18661707639694214),\n",
       " ('humber', 0.16956259310245514),\n",
       " ('english', 0.1593315303325653),\n",
       " ('america', 0.14731059968471527),\n",
       " ('development', 0.14231303334236145),\n",
       " ('ct', 0.12918153405189514),\n",
       " ('svp', 0.1247430071234703)]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Embeddings-Similarity\n",
    "\n",
    "skipgram2.wv.most_similar(positive=['human'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('graduate', 0.23339055478572845),\n",
       " ('university', 0.21716004610061646),\n",
       " ('information', 0.2099626660346985),\n",
       " ('management', 0.20572538673877716),\n",
       " ('sphr', 0.1805756688117981),\n",
       " ('houston', 0.17326371371746063),\n",
       " ('teacher', 0.1715906262397766),\n",
       " ('chapman', 0.15051431953907013),\n",
       " ('engie', 0.14695699512958527),\n",
       " ('major', 0.1438908725976944)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skipgram2.wv.most_similar(positive=['resource'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('chapman', 0.9678015112876892),\n",
       " ('information', 0.962955117225647),\n",
       " ('communication', 0.9569567441940308),\n",
       " ('marketing', 0.9505852460861206),\n",
       " ('management', 0.9505007863044739),\n",
       " ('coordinator', 0.9504880309104919),\n",
       " ('senior', 0.94764643907547),\n",
       " ('manager', 0.9463614225387573),\n",
       " ('aspiring', 0.9455015659332275),\n",
       " ('english', 0.9403043389320374)]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similar words using Fast Text\n",
    "\n",
    "fast_n.wv.most_similar(positive=['human'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('intercontinental', 0.9630917310714722),\n",
       " ('director', 0.9596865177154541),\n",
       " ('senior', 0.9572448134422302),\n",
       " ('generalist', 0.9566609859466553),\n",
       " ('engie', 0.9560286998748779),\n",
       " ('internship', 0.9540278911590576),\n",
       " ('retail', 0.9537052512168884),\n",
       " ('university', 0.9535289406776428),\n",
       " ('professional', 0.9532554745674133),\n",
       " ('development', 0.9530006051063538)]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_n.wv.most_similar(positive=['resource'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to take average of all vectors of each word in job_title so that each job_title can represent (1,100) dimensional vector\n",
    "\n",
    "def get_mean_vector(Model, doc):\n",
    "\n",
    "    words=[word for word in doc if word in Model.wv.index_to_key]\n",
    "    if len(words)>=1:\n",
    "        return np.mean(Model.wv[words], axis=0)\n",
    "    else:\n",
    "        return np.array([0]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001373</td>\n",
       "      <td>-0.001982</td>\n",
       "      <td>-0.004247</td>\n",
       "      <td>-0.004094</td>\n",
       "      <td>-0.002174</td>\n",
       "      <td>-0.004579</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>-0.001693</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006151</td>\n",
       "      <td>0.002115</td>\n",
       "      <td>-0.004247</td>\n",
       "      <td>-0.007120</td>\n",
       "      <td>-0.003030</td>\n",
       "      <td>-0.001254</td>\n",
       "      <td>-0.000302</td>\n",
       "      <td>0.007065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001257</td>\n",
       "      <td>-0.001588</td>\n",
       "      <td>0.003988</td>\n",
       "      <td>-0.003821</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>0.003904</td>\n",
       "      <td>0.001121</td>\n",
       "      <td>0.007306</td>\n",
       "      <td>0.001121</td>\n",
       "      <td>0.001906</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002748</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.003988</td>\n",
       "      <td>0.001216</td>\n",
       "      <td>0.002822</td>\n",
       "      <td>0.003357</td>\n",
       "      <td>-0.000279</td>\n",
       "      <td>-0.001616</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002420</td>\n",
       "      <td>-0.002726</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>0.002990</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.001792</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>0.001078</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007508</td>\n",
       "      <td>-0.002759</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>-0.007188</td>\n",
       "      <td>0.002730</td>\n",
       "      <td>0.001923</td>\n",
       "      <td>0.002951</td>\n",
       "      <td>0.007954</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.006601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002915</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.002957</td>\n",
       "      <td>-0.003792</td>\n",
       "      <td>0.002811</td>\n",
       "      <td>0.005765</td>\n",
       "      <td>0.001853</td>\n",
       "      <td>0.003041</td>\n",
       "      <td>0.001853</td>\n",
       "      <td>0.002950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003112</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>0.002957</td>\n",
       "      <td>-0.002144</td>\n",
       "      <td>0.002879</td>\n",
       "      <td>0.004505</td>\n",
       "      <td>0.005385</td>\n",
       "      <td>-0.009427</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000619</td>\n",
       "      <td>-0.001410</td>\n",
       "      <td>0.002461</td>\n",
       "      <td>-0.002141</td>\n",
       "      <td>-0.002107</td>\n",
       "      <td>0.002988</td>\n",
       "      <td>0.001783</td>\n",
       "      <td>0.004846</td>\n",
       "      <td>0.001783</td>\n",
       "      <td>-0.002436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>-0.003629</td>\n",
       "      <td>0.002461</td>\n",
       "      <td>0.003644</td>\n",
       "      <td>-0.005177</td>\n",
       "      <td>-0.001507</td>\n",
       "      <td>-0.000839</td>\n",
       "      <td>-0.008105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.001373 -0.001982 -0.004247 -0.004094 -0.002174 -0.004579  0.001152   \n",
       "1  0.001257 -0.001588  0.003988 -0.003821 -0.000114  0.003904  0.001121   \n",
       "2  0.002420 -0.002726  0.000705  0.002990  0.000293  0.001792  0.000676   \n",
       "3  0.002915  0.000171  0.002957 -0.003792  0.002811  0.005765  0.001853   \n",
       "4  0.000619 -0.001410  0.002461 -0.002141 -0.002107  0.002988  0.001783   \n",
       "\n",
       "        7         8         9    ...       94        95        96        97   \\\n",
       "0  0.000750  0.001152 -0.001693  ... -0.006151  0.002115 -0.004247 -0.007120   \n",
       "1  0.007306  0.001121  0.001906  ... -0.002748  0.000101  0.003988  0.001216   \n",
       "2  0.001078  0.000676  0.000118  ... -0.007508 -0.002759  0.000705 -0.007188   \n",
       "3  0.003041  0.001853  0.002950  ...  0.003112  0.001119  0.002957 -0.002144   \n",
       "4  0.004846  0.001783 -0.002436  ...  0.000800 -0.003629  0.002461  0.003644   \n",
       "\n",
       "        98        99        100       101  102       103  \n",
       "0 -0.003030 -0.001254 -0.000302  0.007065  0.0  0.001119  \n",
       "1  0.002822  0.003357 -0.000279 -0.001616  0.0  0.006156  \n",
       "2  0.002730  0.001923  0.002951  0.007954  0.0 -0.006601  \n",
       "3  0.002879  0.004505  0.005385 -0.009427  0.0  0.006554  \n",
       "4 -0.005177 -0.001507 -0.000839 -0.008105  0.0  0.009815  \n",
       "\n",
       "[5 rows x 104 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(100, 104)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Job_title to Vectors using Skip Gram Model\n",
    "\n",
    "k_sg= [get_mean_vector(skipgram2,i) for i in data.job_title]\n",
    "\n",
    "k1=pd.DataFrame(k_sg).transpose()\n",
    "\n",
    "k1.head()\n",
    "k1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.003896</td>\n",
       "      <td>-0.006597</td>\n",
       "      <td>-0.006791</td>\n",
       "      <td>-0.006577</td>\n",
       "      <td>-0.005842</td>\n",
       "      <td>-0.006710</td>\n",
       "      <td>-0.005240</td>\n",
       "      <td>-0.006496</td>\n",
       "      <td>-0.005240</td>\n",
       "      <td>-0.006448</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006824</td>\n",
       "      <td>-0.005950</td>\n",
       "      <td>-0.006791</td>\n",
       "      <td>-0.006226</td>\n",
       "      <td>-0.006579</td>\n",
       "      <td>-0.004745</td>\n",
       "      <td>-0.005425</td>\n",
       "      <td>-0.007084</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.007608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006873</td>\n",
       "      <td>0.007489</td>\n",
       "      <td>0.007601</td>\n",
       "      <td>0.007967</td>\n",
       "      <td>0.006454</td>\n",
       "      <td>0.007574</td>\n",
       "      <td>0.008082</td>\n",
       "      <td>0.008671</td>\n",
       "      <td>0.008082</td>\n",
       "      <td>0.006864</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006866</td>\n",
       "      <td>0.007638</td>\n",
       "      <td>0.007601</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.006414</td>\n",
       "      <td>0.006950</td>\n",
       "      <td>0.007864</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.010979</td>\n",
       "      <td>-0.011625</td>\n",
       "      <td>-0.012338</td>\n",
       "      <td>-0.013006</td>\n",
       "      <td>-0.010355</td>\n",
       "      <td>-0.011764</td>\n",
       "      <td>-0.012067</td>\n",
       "      <td>-0.013423</td>\n",
       "      <td>-0.012067</td>\n",
       "      <td>-0.012593</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011069</td>\n",
       "      <td>-0.012379</td>\n",
       "      <td>-0.012338</td>\n",
       "      <td>-0.011517</td>\n",
       "      <td>-0.012740</td>\n",
       "      <td>-0.012004</td>\n",
       "      <td>-0.012564</td>\n",
       "      <td>-0.009537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.014425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003486</td>\n",
       "      <td>0.003552</td>\n",
       "      <td>0.002884</td>\n",
       "      <td>0.002669</td>\n",
       "      <td>0.003123</td>\n",
       "      <td>0.003234</td>\n",
       "      <td>0.002296</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.002296</td>\n",
       "      <td>0.002322</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001831</td>\n",
       "      <td>0.002903</td>\n",
       "      <td>0.002884</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>0.002082</td>\n",
       "      <td>0.003402</td>\n",
       "      <td>0.003157</td>\n",
       "      <td>-0.000348</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.002789</td>\n",
       "      <td>-0.003070</td>\n",
       "      <td>-0.002167</td>\n",
       "      <td>-0.002314</td>\n",
       "      <td>-0.003086</td>\n",
       "      <td>-0.002725</td>\n",
       "      <td>-0.002664</td>\n",
       "      <td>-0.002713</td>\n",
       "      <td>-0.002664</td>\n",
       "      <td>-0.003123</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002715</td>\n",
       "      <td>-0.003254</td>\n",
       "      <td>-0.002167</td>\n",
       "      <td>-0.002418</td>\n",
       "      <td>-0.003615</td>\n",
       "      <td>-0.003450</td>\n",
       "      <td>-0.003234</td>\n",
       "      <td>-0.002712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.003912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.003896 -0.006597 -0.006791 -0.006577 -0.005842 -0.006710 -0.005240   \n",
       "1  0.006873  0.007489  0.007601  0.007967  0.006454  0.007574  0.008082   \n",
       "2 -0.010979 -0.011625 -0.012338 -0.013006 -0.010355 -0.011764 -0.012067   \n",
       "3  0.003486  0.003552  0.002884  0.002669  0.003123  0.003234  0.002296   \n",
       "4 -0.002789 -0.003070 -0.002167 -0.002314 -0.003086 -0.002725 -0.002664   \n",
       "\n",
       "        7         8         9    ...       94        95        96        97   \\\n",
       "0 -0.006496 -0.005240 -0.006448  ... -0.006824 -0.005950 -0.006791 -0.006226   \n",
       "1  0.008671  0.008082  0.006864  ...  0.006866  0.007638  0.007601  0.007968   \n",
       "2 -0.013423 -0.012067 -0.012593  ... -0.011069 -0.012379 -0.012338 -0.011517   \n",
       "3  0.003906  0.002296  0.002322  ...  0.001831  0.002903  0.002884  0.000795   \n",
       "4 -0.002713 -0.002664 -0.003123  ... -0.002715 -0.003254 -0.002167 -0.002418   \n",
       "\n",
       "        98        99        100       101  102       103  \n",
       "0 -0.006579 -0.004745 -0.005425 -0.007084  0.0 -0.007608  \n",
       "1  0.006414  0.006950  0.007864  0.004902  0.0  0.006708  \n",
       "2 -0.012740 -0.012004 -0.012564 -0.009537  0.0 -0.014425  \n",
       "3  0.002082  0.003402  0.003157 -0.000348  0.0  0.003989  \n",
       "4 -0.003615 -0.003450 -0.003234 -0.002712  0.0 -0.003912  \n",
       "\n",
       "[5 rows x 104 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(100, 104)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_ft= []\n",
    "for i in data.job_title:\n",
    "    k_ft.append(list(get_mean_vector(fast_n,i)))\n",
    "\n",
    "k2=pd.DataFrame(k_ft).transpose()\n",
    "\n",
    "k2.head()\n",
    "k2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 104)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skipgram_vectors=k2.to_numpy()\n",
    "skipgram_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine Similarity Function\n",
    "\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cos_similarity(a,b):\n",
    "    return np.dot(a,b)/(norm(a)*norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess User's input query\n",
    "\n",
    "\n",
    "def Input_preprocessor(query, model):\n",
    "    query= preprocess(query)\n",
    "    input_vec=get_mean_vector(model, query)\n",
    "    return input_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciton to return n similar results\n",
    "\n",
    "\n",
    "# Query= User's input\n",
    "# vec= Skip gram vectors\n",
    "# df= orifinal data\n",
    "# Model= trained model\n",
    "\n",
    "def Top_n(query, model, skipgram_vectors,data):\n",
    "\n",
    "    query=Input_preprocessor(query,model)\n",
    "\n",
    "    x=[]\n",
    "    for i in range(len(skipgram_vectors)):\n",
    "        x.append(cosine_similarity(query, skipgram_vectors[i]))\n",
    "\n",
    "    #x= [cosine_similarity(query,i) for i in skipgram_vectors]    \n",
    "\n",
    "    temp=list(x)   \n",
    "\n",
    "    return temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 100)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(len(skipgram_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=(skipgram_vectors.T[3])\n",
    "type(i)\n",
    "i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query=Input_preprocessor(\"Aspiring human resources\",skipgram2)\n",
    "type(query)\n",
    "query.shape\n",
    "\n",
    "#x= [cosine_similarity(query,i) for i in skipgram_vectors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (100,) and (104,) not aligned: 100 (dim 0) != 104 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\97158\\Desktop\\Apziva\\Project 3- Potential Talents\\Potential Talents.ipynb Cell 63\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/97158/Desktop/Apziva/Project%203-%20Potential%20Talents/Potential%20Talents.ipynb#Y131sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m Q\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mdot(query,skipgram_vectors[\u001b[39m6\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/97158/Desktop/Apziva/Project%203-%20Potential%20Talents/Potential%20Talents.ipynb#Y131sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m w\u001b[39m=\u001b[39m(norm(query)\u001b[39m*\u001b[39mnorm(skipgram_vectors))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/97158/Desktop/Apziva/Project%203-%20Potential%20Talents/Potential%20Talents.ipynb#Y131sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m Q\u001b[39m.\u001b[39mshape\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (100,) and (104,) not aligned: 100 (dim 0) != 104 (dim 0)"
     ]
    }
   ],
   "source": [
    "Q=np.dot(query,skipgram_vectors[6])\n",
    "w=(norm(query)*norm(skipgram_vectors))\n",
    "Q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspiring human resources\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'Word2Vec' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mUntitled-1.ipynb Cell 60\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#Y144sdW50aXRsZWQ%3D?line=0'>1</a>\u001b[0m Q1\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mAspiring human resources\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#Y144sdW50aXRsZWQ%3D?line=2'>3</a>\u001b[0m results, sim\u001b[39m=\u001b[39mtop_n(Q1, skipgram2,data)\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#Y144sdW50aXRsZWQ%3D?line=3'>4</a>\u001b[0m results\n",
      "\u001b[1;32mUntitled-1.ipynb Cell 60\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#Y144sdW50aXRsZWQ%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(query)\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#Y144sdW50aXRsZWQ%3D?line=3'>4</a>\u001b[0m x\u001b[39m=\u001b[39m[]\n\u001b[1;32m----> <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#Y144sdW50aXRsZWQ%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(p)):\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#Y144sdW50aXRsZWQ%3D?line=5'>6</a>\u001b[0m     x\u001b[39m.\u001b[39mappend(cos_sim(query,p[i]))\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#Y144sdW50aXRsZWQ%3D?line=7'>8</a>\u001b[0m tmp\u001b[39m=\u001b[39m\u001b[39mlist\u001b[39m(x)\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'Word2Vec' has no len()"
     ]
    }
   ],
   "source": [
    "Q1= \"Aspiring human resources\"\n",
    "\n",
    "results, sim=top_n(Q1, skipgram2,data)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   #Sorting the list\n",
    "\n",
    "#     sort=sorted(range(len(x)),key=lambda sub: x[sub])    \n",
    "#     sim=[temp[i] for i in reversed(sort)]\n",
    "#     print(sim)\n",
    "\n",
    "#     # Getting index of the top 10\n",
    "#     Ind=[]\n",
    "#     for i in reversed(sort):\n",
    "#         Ind.append(i)\n",
    "\n",
    "#     return data.iloc[Ind,[1,2,3,4]], sim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
