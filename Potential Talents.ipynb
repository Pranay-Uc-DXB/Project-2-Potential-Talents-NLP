{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to get multiple outputs in the same cell\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity='all'\n",
    "\n",
    "#Code to ignore all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings(action='ignore',category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019 C.T. Bauer College of Business Graduate (...</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Native English Teacher at EPIK (English Progra...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>People Development Coordinator at Ryan</td>\n",
       "      <td>Denton, Texas</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>İzmir, Türkiye</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                          job_title  \\\n",
       "0   1  2019 C.T. Bauer College of Business Graduate (...   \n",
       "1   2  Native English Teacher at EPIK (English Progra...   \n",
       "2   3              Aspiring Human Resources Professional   \n",
       "3   4             People Development Coordinator at Ryan   \n",
       "4   5    Advisory Board Member at Celal Bayar University   \n",
       "\n",
       "                              location connection  fit  \n",
       "0                       Houston, Texas         85  NaN  \n",
       "1                               Kanada      500+   NaN  \n",
       "2  Raleigh-Durham, North Carolina Area         44  NaN  \n",
       "3                        Denton, Texas      500+   NaN  \n",
       "4                       İzmir, Türkiye      500+   NaN  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(r\"C:\\Users\\97158\\Desktop\\Apziva\\Project 3- Potential Talents\\potential-talents - Aspiring human resources - seeking human resources.csv\")\n",
    "data.head()\n",
    "data1=data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.drop('fit', axis=1)\n",
    "y=data['fit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing relevant libraries\n",
    "\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk. stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_title=list(X['job_title'])\n",
    "len(job_title)\n",
    "job_title[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019 c.t. bauer college of business graduate (magna cum laude) and aspiring human resources professional'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of first job_title:  104\n"
     ]
    }
   ],
   "source": [
    "#Making all text lower case\n",
    "\n",
    "job_title_LowC=[word.lower() for word in job_title]\n",
    "job_title_LowC[0]\n",
    "print(\"Length of first job_title: \",len(job_title_LowC[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2019',\n",
       " 'c.t',\n",
       " '.',\n",
       " 'bauer',\n",
       " 'college',\n",
       " 'of',\n",
       " 'business',\n",
       " 'graduate',\n",
       " '(',\n",
       " 'magna',\n",
       " 'cum',\n",
       " 'laude',\n",
       " ')',\n",
       " 'and',\n",
       " 'aspiring',\n",
       " 'human',\n",
       " 'resources',\n",
       " 'professional']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of first job_title:  18\n"
     ]
    }
   ],
   "source": [
    "# tokenize doc in list(job_title)\n",
    "\n",
    "tokens= [word_tokenize(word) for word in job_title_LowC]\n",
    "tokens[0]\n",
    "print(\"Length of first job_title: \",len(tokens[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing stop words in the document\n",
    "\n",
    "sw=stopwords.words('english')\n",
    "sw[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2019',\n",
       " 'c.t',\n",
       " '.',\n",
       " 'bauer',\n",
       " 'college',\n",
       " 'business',\n",
       " 'graduate',\n",
       " '(',\n",
       " 'magna',\n",
       " 'cum',\n",
       " 'laude',\n",
       " ')',\n",
       " 'aspiring',\n",
       " 'human',\n",
       " 'resources',\n",
       " 'professional']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of first job_title:  16\n"
     ]
    }
   ],
   "source": [
    "# removing stopwords from each doc in list(job_title)\n",
    "# doc in list\n",
    "# words in doc\n",
    "\n",
    "tokens= [[word for word in doc if word not in sw] for doc in tokens]\n",
    "tokens[0]\n",
    "print(\"Length of first job_title: \",len(tokens[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Punctuation\n",
    "\n",
    "tokenizer=RegexpTokenizer(r'\\w+')\n",
    "tokens=[[\"\".join(tokenizer.tokenize(word)) for word in doc if len(tokenizer.tokenize(word))>0] for doc in tokens]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2019',\n",
       " 'ct',\n",
       " 'bauer',\n",
       " 'college',\n",
       " 'business',\n",
       " 'graduate',\n",
       " 'magna',\n",
       " 'cum',\n",
       " 'laude',\n",
       " 'aspiring',\n",
       " 'human',\n",
       " 'resources',\n",
       " 'professional']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of first job_title:  13\n"
     ]
    }
   ],
   "source": [
    "tokens[0]\n",
    "print(\"Length of first job_title: \",len(tokens[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming\n",
    "\n",
    "porter=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2019',\n",
       " 'ct',\n",
       " 'bauer',\n",
       " 'colleg',\n",
       " 'busi',\n",
       " 'graduat',\n",
       " 'magna',\n",
       " 'cum',\n",
       " 'laud',\n",
       " 'aspir',\n",
       " 'human',\n",
       " 'resourc',\n",
       " 'profession']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of first job_title:  13\n"
     ]
    }
   ],
   "source": [
    "# Finding root words across documents\n",
    "# tokens in docs\n",
    "# words in docs\n",
    "\n",
    "\n",
    "tokens= [[porter.stem(word) for word in doc] for doc in tokens]\n",
    "\n",
    "tokens[0]\n",
    "print(\"Length of first job_title: \",len(tokens[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019 ct bauer colleg busi graduat magna cum laud aspir human resourc profession'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of all job_titles:  104\n"
     ]
    }
   ],
   "source": [
    "# Implementing Bag of words\n",
    "\n",
    "Clean_job_title=[\" \".join(word) for word in tokens]\n",
    "Clean_job_title[0]\n",
    "\n",
    "print(\"Length of all job_titles: \",len(Clean_job_title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104, 35)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "scipy.sparse._csr.csr_matrix"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "sklearn.feature_extraction.text.CountVectorizer"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect=CountVectorizer(binary=True, min_df=5)\n",
    "\n",
    "matrix=vect.fit_transform(Clean_job_title)\n",
    "\n",
    "matrix.shape  #Returns x and y where x is the total number of tekens and y is the count of binary tokens appearing it atleast 5 documents\n",
    "type(matrix)\n",
    "type(vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above x and y shape pertains to x being the total number of tokens and y being the count of binary tokens appearing it atleast 5 documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the number of unique words in the library\n",
    "len(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104, 35)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array(<104x35 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 427 stored elements in Compressed Sparse Row format>, dtype=object)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting Sparse Matrix into Array\n",
    "\n",
    "x_array=matrix\n",
    "g=np.squeeze(np.asarray(matrix))\n",
    "\n",
    "x_array.shape\n",
    "g.shape\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cos_sim=cosine_similarity(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.       , 0.       , 0.5547002, ..., 0.2773501, 0.       ,\n",
       "        0.       ],\n",
       "       [0.       , 1.       , 0.       , ..., 0.       , 0.       ,\n",
       "        0.       ],\n",
       "       [0.5547002, 0.       , 1.       , ..., 0.       , 0.       ,\n",
       "        0.       ],\n",
       "       ...,\n",
       "       [0.2773501, 0.       , 0.       , ..., 1.       , 0.       ,\n",
       "        0.       ],\n",
       "       [0.       , 0.       , 0.       , ..., 0.       , 0.       ,\n",
       "        0.       ],\n",
       "       [0.       , 0.       , 0.       , ..., 0.       , 0.       ,\n",
       "        0.       ]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "cos_sim1=linear_kernel(matrix, matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13.,  0.,  4., ...,  1.,  0.,  0.],\n",
       "       [ 0.,  6.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 4.,  0.,  4., ...,  0.,  0.,  0.],\n",
       "       ...,\n",
       "       [ 1.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Recommendation Engine\n",
    "\n",
    "# def recommend(job_title, cosine_similarity=cos_sim):\n",
    "#     index = Clean_job_title.index(job_title)\n",
    "#     sim_score = list(enumerate(cos_sim[index]))\n",
    "#     sim_score = sorted(sim_score, key= lambda x: x[1], reverse=True)[1:11] #position 0 is the movie itself, thus exclude\n",
    "#     recommend_index = [i[0] for i in sim_score]\n",
    "#     rec_movie = data['job_title'].iloc[recommend_index]\n",
    "#     rec_score = [round(i[1],4) for i in sim_score]\n",
    "#     rec_table = pd.DataFrame(list(zip(rec_movie,rec_score)), columns=['Recommend Candidate','Similarity(0-1)'])\n",
    "#     return rec_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Recommendation Engine\n",
    "\n",
    "# from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# def find_similar(tfidf_matrix, index, top_n = 5):\n",
    "#     cosine_similarities = linear_kernel(tfidf_matrix[index:index+1], tfidf_matrix).flatten()\n",
    "#     related_docs_indices = [i for i in cosine_similarities.argsort()[::-1] if i != index]\n",
    "#     return [(index, cosine_similarities[index]) for index in related_docs_indices][0:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cos_sim(a,b):\n",
    "\n",
    "    return dot(a, b)/(norm(a)*norm(b)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Potential Talents -- Project starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to clean the text\n",
    "\n",
    "\n",
    "# Function to to make all text lowercase\n",
    "def make_lowercase(text):\n",
    "    lower=list(text)\n",
    "    lower= [doc.lower() for doc in text]\n",
    "    return lower\n",
    "\n",
    "#Removing numbers\n",
    "def remove_numbers(text):\n",
    "    remover=[[re.sub(r'\\d+','',word) for word in doc] for doc in text]\n",
    "    #remover=re.sub(r'\\d+','',text) # \\d+ removes numbers. re.sub finds and replaces that pattern in text. Takes 3 arguments \n",
    "    return remover\n",
    "\n",
    "#Removing punctuations\n",
    "regex=RegexpTokenizer(r'\\w+')\n",
    "def remove_punctuations(text):\n",
    "    removed_punct= [[\"\".join(regex.tokenize(word)) for word in doc if len(regex.tokenize(word))>0] for doc in text]  \n",
    "    return removed_punct\n",
    "\n",
    "#Removing Stop Words\n",
    "stop_words=stopwords.words('english')\n",
    "def remove_stopwords(text):\n",
    "    sw_remover=[[word for word in doc if word not in stop_words] for doc in text]\n",
    "    return sw_remover\n",
    "\n",
    "\n",
    "#Tokenizing texts\n",
    "def tokenize(text):\n",
    "    tokens=[word_tokenize(doc) for doc in text]\n",
    "    return tokens\n",
    "\n",
    "#Lemmatize Words\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "def root(text):\n",
    "    #flattened_text=[word for sublist in text for word in sublist]\n",
    "    #lemmatized_text=[lemmatizer.lemmatize(word) for word in flattened_text]\n",
    "    # text= [lemmatizer.lemmatize(word) for word_list in text for word in word_list]\n",
    "    lem_text= [[lemmatizer.lemmatize(word) for word in doc] for doc in text]\n",
    "    return lem_text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Compiling all the above def functions to preprocess all in one step\n",
    "\n",
    "def preprocess(text):\n",
    "\n",
    "    text=make_lowercase(text)\n",
    "    text=tokenize(text)\n",
    "    text=remove_stopwords(text)\n",
    "    text=remove_punctuations(text)\n",
    "    text=remove_numbers(text)\n",
    "    text=root(text)\n",
    "  \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['job_title']=preprocess(data['job_title'])\n",
    "data['location']=preprocess(data['location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[, ct, bauer, college, business, graduate, mag...</td>\n",
       "      <td>[houston, texas]</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[native, english, teacher, epik, english, prog...</td>\n",
       "      <td>[kanada]</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[aspiring, human, resource, professional]</td>\n",
       "      <td>[raleighdurham, north, carolina, area]</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[people, development, coordinator, ryan]</td>\n",
       "      <td>[denton, texas]</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[advisory, board, member, celal, bayar, univer...</td>\n",
       "      <td>[izmir, türkiye]</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                          job_title  \\\n",
       "0   1  [, ct, bauer, college, business, graduate, mag...   \n",
       "1   2  [native, english, teacher, epik, english, prog...   \n",
       "2   3          [aspiring, human, resource, professional]   \n",
       "3   4           [people, development, coordinator, ryan]   \n",
       "4   5  [advisory, board, member, celal, bayar, univer...   \n",
       "\n",
       "                                 location connection  fit  \n",
       "0                        [houston, texas]         85  NaN  \n",
       "1                                [kanada]      500+   NaN  \n",
       "2  [raleighdurham, north, carolina, area]         44  NaN  \n",
       "3                         [denton, texas]      500+   NaN  \n",
       "4                        [izmir, türkiye]      500+   NaN  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('human', 63),\n",
       " ('resource', 63),\n",
       " ('aspiring', 35),\n",
       " ('professional', 21),\n",
       " ('student', 16),\n",
       " ('seeking', 15),\n",
       " ('college', 14),\n",
       " ('generalist', 14),\n",
       " ('university', 12),\n",
       " ('specialist', 12)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_tokens=[word for t in data['job_title'] for word in t]\n",
    "counts=Counter(flat_tokens)\n",
    "\n",
    "counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data.job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec<vocab=67, vector_size=100, alpha=0.025>\n"
     ]
    }
   ],
   "source": [
    "# Training Skip Gram Model\n",
    "\n",
    "skipgram2=Word2Vec(x,vector_size=100,window=1,min_count=2,sg=1)\n",
    "\n",
    "#Window=3 means model will consider 1 word at a time while training\n",
    "#min_count=2 means that words that appear at least twice will be included in the vocab.\n",
    "\n",
    "print(skipgram2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText<vocab=67, vector_size=100, alpha=0.025>\n"
     ]
    }
   ],
   "source": [
    "# Training FastText Model\n",
    "\n",
    "fast_n= FastText(x, vector_size=100, window=2, min_count=2, min_n=1, max_n=2, sg=1)\n",
    "\n",
    "# A large window size allows the model to look at more context\n",
    "\n",
    "print(fast_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('marketing', 0.203652024269104),\n",
       " ('bauer', 0.1899968385696411),\n",
       " ('manager', 0.18948908150196075),\n",
       " ('hr', 0.18661707639694214),\n",
       " ('humber', 0.16956259310245514),\n",
       " ('english', 0.1593315303325653),\n",
       " ('america', 0.14731059968471527),\n",
       " ('development', 0.14231303334236145),\n",
       " ('ct', 0.12918153405189514),\n",
       " ('svp', 0.1247430071234703)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Embeddings-Similarity\n",
    "\n",
    "skipgram2.wv.most_similar(positive=['human'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('graduate', 0.23339055478572845),\n",
       " ('university', 0.21716004610061646),\n",
       " ('information', 0.2099626660346985),\n",
       " ('management', 0.20572538673877716),\n",
       " ('sphr', 0.1805756688117981),\n",
       " ('houston', 0.17326371371746063),\n",
       " ('teacher', 0.1715906262397766),\n",
       " ('chapman', 0.15051431953907013),\n",
       " ('engie', 0.14695699512958527),\n",
       " ('major', 0.1438908725976944)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skipgram2.wv.most_similar(positive=['resource'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('chapman', 0.9678015112876892),\n",
       " ('information', 0.962955117225647),\n",
       " ('communication', 0.9569567441940308),\n",
       " ('marketing', 0.9505852460861206),\n",
       " ('management', 0.9505007863044739),\n",
       " ('coordinator', 0.9504880309104919),\n",
       " ('senior', 0.94764643907547),\n",
       " ('manager', 0.9463614225387573),\n",
       " ('aspiring', 0.9455015659332275),\n",
       " ('english', 0.9403043389320374)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similar words using Fast Text\n",
    "\n",
    "fast_n.wv.most_similar(positive=['human'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('intercontinental', 0.9630917310714722),\n",
       " ('director', 0.9596865177154541),\n",
       " ('senior', 0.9572448134422302),\n",
       " ('generalist', 0.9566609859466553),\n",
       " ('engie', 0.9560286998748779),\n",
       " ('internship', 0.9540278911590576),\n",
       " ('retail', 0.9537052512168884),\n",
       " ('university', 0.9535289406776428),\n",
       " ('professional', 0.9532554745674133),\n",
       " ('development', 0.9530006051063538)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_n.wv.most_similar(positive=['resource'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to take average of all vectors of each word in job_title so that each job_title can represent (1,100) dimensional vector\n",
    "\n",
    "def get_mean_vector(Model, doc):\n",
    "\n",
    "    words=[word for word in doc if word in Model.wv.index_to_key]\n",
    "    if len(words)>=1:\n",
    "        return np.mean(Model.wv[words], axis=0)\n",
    "    else:\n",
    "        return np.array([0]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001373</td>\n",
       "      <td>0.001257</td>\n",
       "      <td>0.002420</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>0.000619</td>\n",
       "      <td>-0.002385</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.004634</td>\n",
       "      <td>-0.002674</td>\n",
       "      <td>-0.002347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002584</td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.001866</td>\n",
       "      <td>0.002159</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>-0.001466</td>\n",
       "      <td>-0.000833</td>\n",
       "      <td>-0.000884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001982</td>\n",
       "      <td>-0.001588</td>\n",
       "      <td>-0.002726</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>-0.001410</td>\n",
       "      <td>-0.003116</td>\n",
       "      <td>-0.003762</td>\n",
       "      <td>-0.001297</td>\n",
       "      <td>-0.000839</td>\n",
       "      <td>-0.002577</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002314</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.001983</td>\n",
       "      <td>-0.001088</td>\n",
       "      <td>-0.000713</td>\n",
       "      <td>-0.000339</td>\n",
       "      <td>0.001755</td>\n",
       "      <td>-0.002603</td>\n",
       "      <td>-0.001743</td>\n",
       "      <td>-0.000193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.004247</td>\n",
       "      <td>0.003988</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>0.002957</td>\n",
       "      <td>0.002461</td>\n",
       "      <td>-0.002954</td>\n",
       "      <td>0.001605</td>\n",
       "      <td>0.006620</td>\n",
       "      <td>-0.002920</td>\n",
       "      <td>-0.003184</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001836</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.003524</td>\n",
       "      <td>-0.003551</td>\n",
       "      <td>0.006237</td>\n",
       "      <td>0.003273</td>\n",
       "      <td>0.001989</td>\n",
       "      <td>-0.004040</td>\n",
       "      <td>-0.000901</td>\n",
       "      <td>-0.000492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.004094</td>\n",
       "      <td>-0.003821</td>\n",
       "      <td>0.002990</td>\n",
       "      <td>-0.003792</td>\n",
       "      <td>-0.002141</td>\n",
       "      <td>-0.000399</td>\n",
       "      <td>0.001824</td>\n",
       "      <td>0.003851</td>\n",
       "      <td>-0.000836</td>\n",
       "      <td>-0.002072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004366</td>\n",
       "      <td>-0.006215</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.005846</td>\n",
       "      <td>-0.001066</td>\n",
       "      <td>-0.002541</td>\n",
       "      <td>0.008006</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>0.004586</td>\n",
       "      <td>0.002613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.002174</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.002811</td>\n",
       "      <td>-0.002107</td>\n",
       "      <td>-0.004303</td>\n",
       "      <td>0.000618</td>\n",
       "      <td>0.002775</td>\n",
       "      <td>-0.001485</td>\n",
       "      <td>-0.003718</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002469</td>\n",
       "      <td>0.002407</td>\n",
       "      <td>-0.000705</td>\n",
       "      <td>0.002431</td>\n",
       "      <td>0.005171</td>\n",
       "      <td>-0.001168</td>\n",
       "      <td>-0.006071</td>\n",
       "      <td>0.002218</td>\n",
       "      <td>-0.001742</td>\n",
       "      <td>0.000862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.001373  0.001257  0.002420  0.002915  0.000619 -0.002385  0.000024   \n",
       "1 -0.001982 -0.001588 -0.002726  0.000171 -0.001410 -0.003116 -0.003762   \n",
       "2 -0.004247  0.003988  0.000705  0.002957  0.002461 -0.002954  0.001605   \n",
       "3 -0.004094 -0.003821  0.002990 -0.003792 -0.002141 -0.000399  0.001824   \n",
       "4 -0.002174 -0.000114  0.000293  0.002811 -0.002107 -0.004303  0.000618   \n",
       "\n",
       "         7         8         9   ...        90        91        92        93  \\\n",
       "0  0.004634 -0.002674 -0.002347  ...  0.002584 -0.000047  0.000781  0.000900   \n",
       "1 -0.001297 -0.000839 -0.002577  ...  0.002314  0.002404  0.001983 -0.001088   \n",
       "2  0.006620 -0.002920 -0.003184  ... -0.001836  0.000672  0.003524 -0.003551   \n",
       "3  0.003851 -0.000836 -0.002072  ...  0.004366 -0.006215 -0.000055 -0.005846   \n",
       "4  0.002775 -0.001485 -0.003718  ...  0.002469  0.002407 -0.000705  0.002431   \n",
       "\n",
       "         94        95        96        97        98        99  \n",
       "0  0.001866  0.002159  0.000299 -0.001466 -0.000833 -0.000884  \n",
       "1 -0.000713 -0.000339  0.001755 -0.002603 -0.001743 -0.000193  \n",
       "2  0.006237  0.003273  0.001989 -0.004040 -0.000901 -0.000492  \n",
       "3 -0.001066 -0.002541  0.008006  0.001028  0.004586  0.002613  \n",
       "4  0.005171 -0.001168 -0.006071  0.002218 -0.001742  0.000862  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(104, 100)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Job_title to Vectors using Skip Gram Model\n",
    "\n",
    "sg_mean= [get_mean_vector(skipgram2,i) for i in data.job_title]\n",
    "skipg_mean=pd.DataFrame(sg_mean)\n",
    "\n",
    "skipg_mean.head()\n",
    "skipg_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.003896</td>\n",
       "      <td>0.006873</td>\n",
       "      <td>-0.010979</td>\n",
       "      <td>0.003486</td>\n",
       "      <td>-0.002789</td>\n",
       "      <td>-0.003376</td>\n",
       "      <td>0.001189</td>\n",
       "      <td>-0.001066</td>\n",
       "      <td>0.005136</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008723</td>\n",
       "      <td>-0.003084</td>\n",
       "      <td>0.004119</td>\n",
       "      <td>0.002535</td>\n",
       "      <td>0.001942</td>\n",
       "      <td>0.004532</td>\n",
       "      <td>-0.006140</td>\n",
       "      <td>0.002993</td>\n",
       "      <td>-0.002063</td>\n",
       "      <td>-0.000105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.006597</td>\n",
       "      <td>0.007489</td>\n",
       "      <td>-0.011625</td>\n",
       "      <td>0.003552</td>\n",
       "      <td>-0.003070</td>\n",
       "      <td>-0.003396</td>\n",
       "      <td>0.002458</td>\n",
       "      <td>-0.000059</td>\n",
       "      <td>0.006260</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009276</td>\n",
       "      <td>-0.003348</td>\n",
       "      <td>0.006073</td>\n",
       "      <td>0.002382</td>\n",
       "      <td>0.002381</td>\n",
       "      <td>0.004785</td>\n",
       "      <td>-0.005924</td>\n",
       "      <td>0.002485</td>\n",
       "      <td>-0.003362</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.006791</td>\n",
       "      <td>0.007601</td>\n",
       "      <td>-0.012338</td>\n",
       "      <td>0.002884</td>\n",
       "      <td>-0.002167</td>\n",
       "      <td>-0.004100</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>0.006197</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009625</td>\n",
       "      <td>-0.003667</td>\n",
       "      <td>0.005863</td>\n",
       "      <td>0.002772</td>\n",
       "      <td>0.003214</td>\n",
       "      <td>0.006968</td>\n",
       "      <td>-0.006235</td>\n",
       "      <td>0.002630</td>\n",
       "      <td>-0.003245</td>\n",
       "      <td>-0.000507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.006577</td>\n",
       "      <td>0.007967</td>\n",
       "      <td>-0.013006</td>\n",
       "      <td>0.002669</td>\n",
       "      <td>-0.002314</td>\n",
       "      <td>-0.004006</td>\n",
       "      <td>0.003616</td>\n",
       "      <td>-0.000570</td>\n",
       "      <td>0.006656</td>\n",
       "      <td>-0.000872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009490</td>\n",
       "      <td>-0.003293</td>\n",
       "      <td>0.006551</td>\n",
       "      <td>0.003259</td>\n",
       "      <td>0.002938</td>\n",
       "      <td>0.004796</td>\n",
       "      <td>-0.007104</td>\n",
       "      <td>0.003625</td>\n",
       "      <td>-0.002344</td>\n",
       "      <td>-0.000497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.005842</td>\n",
       "      <td>0.006454</td>\n",
       "      <td>-0.010355</td>\n",
       "      <td>0.003123</td>\n",
       "      <td>-0.003086</td>\n",
       "      <td>-0.003537</td>\n",
       "      <td>0.002135</td>\n",
       "      <td>-0.000331</td>\n",
       "      <td>0.004739</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009224</td>\n",
       "      <td>-0.003087</td>\n",
       "      <td>0.005941</td>\n",
       "      <td>0.000973</td>\n",
       "      <td>0.002310</td>\n",
       "      <td>0.004737</td>\n",
       "      <td>-0.005045</td>\n",
       "      <td>0.002923</td>\n",
       "      <td>-0.002246</td>\n",
       "      <td>0.000787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.003896  0.006873 -0.010979  0.003486 -0.002789 -0.003376  0.001189   \n",
       "1 -0.006597  0.007489 -0.011625  0.003552 -0.003070 -0.003396  0.002458   \n",
       "2 -0.006791  0.007601 -0.012338  0.002884 -0.002167 -0.004100  0.000654   \n",
       "3 -0.006577  0.007967 -0.013006  0.002669 -0.002314 -0.004006  0.003616   \n",
       "4 -0.005842  0.006454 -0.010355  0.003123 -0.003086 -0.003537  0.002135   \n",
       "\n",
       "         7         8         9   ...        90        91        92        93  \\\n",
       "0 -0.001066  0.005136  0.000434  ...  0.008723 -0.003084  0.004119  0.002535   \n",
       "1 -0.000059  0.006260  0.000961  ...  0.009276 -0.003348  0.006073  0.002382   \n",
       "2 -0.000045  0.006197  0.000242  ...  0.009625 -0.003667  0.005863  0.002772   \n",
       "3 -0.000570  0.006656 -0.000872  ...  0.009490 -0.003293  0.006551  0.003259   \n",
       "4 -0.000331  0.004739  0.000866  ...  0.009224 -0.003087  0.005941  0.000973   \n",
       "\n",
       "         94        95        96        97        98        99  \n",
       "0  0.001942  0.004532 -0.006140  0.002993 -0.002063 -0.000105  \n",
       "1  0.002381  0.004785 -0.005924  0.002485 -0.003362  0.000035  \n",
       "2  0.003214  0.006968 -0.006235  0.002630 -0.003245 -0.000507  \n",
       "3  0.002938  0.004796 -0.007104  0.003625 -0.002344 -0.000497  \n",
       "4  0.002310  0.004737 -0.005045  0.002923 -0.002246  0.000787  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(104, 100)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Job_title to Vectors using FasttText Model\n",
    "\n",
    "ft_mean= [get_mean_vector(fast_n,i) for i in data.job_title]\n",
    "\n",
    "fastT_mean=pd.DataFrame(ft_mean)\n",
    "\n",
    "fastT_mean.head()\n",
    "fastT_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104, 100)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_text_vectors=fastT_mean.to_numpy()\n",
    "fast_text_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine Similarity Function\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess User's input query\n",
    "\n",
    "\n",
    "def Input_preprocessor(query, model):\n",
    "    query= preprocess(query)\n",
    "    input_vec=get_mean_vector(model, query)\n",
    "    return input_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciton to return n similar results\n",
    "\n",
    "\n",
    "# Query= User's input\n",
    "# vec= Skip gram vectors\n",
    "# df= orifinal data\n",
    "# Model= trained model\n",
    "\n",
    "def Top_n(query, model, vectors,data):\n",
    "\n",
    "    query = Input_preprocessor(query, model)\n",
    "\n",
    "    x = []\n",
    "    for i in range(len(vectors)):\n",
    "        # Reshape both query and row_vector to ensure compatible shapes for cosine similarity\n",
    "        query_reshaped = query.reshape(1, -1)\n",
    "        row_vector_reshaped = vectors[i].reshape(1, -1)\n",
    "\n",
    "        similarity = cosine_similarity(query_reshaped, row_vector_reshaped)\n",
    "        x.append(similarity)\n",
    "\n",
    "    temp = list(x)\n",
    "\n",
    "    #Sorting the list\n",
    "\n",
    "    sort=temp.sort(reverse=True)[:10]\n",
    "    sim=[temp[i] for i in reversed(sort)]\n",
    "    print(sim)\n",
    "\n",
    "    sort=sorted(range(len(x)),key=lambda sub: x[sub])[-10:]    \n",
    "    sim=[temp[i] for i in reversed(sort)]\n",
    "    print(sim)\n",
    "\n",
    "    # Getting index of the top 10\n",
    "    Ind=[]\n",
    "    for i in reversed(sort):\n",
    "        Ind.append(i)\n",
    "\n",
    "    return  data.iloc[Ind,[1,2,3,4]], sim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\97158\\Desktop\\Apziva\\Project 3- Potential Talents\\Potential Talents.ipynb Cell 55\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/97158/Desktop/Apziva/Project%203-%20Potential%20Talents/Potential%20Talents.ipynb#Y104sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m Q1\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mAspiring human resources\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/97158/Desktop/Apziva/Project%203-%20Potential%20Talents/Potential%20Talents.ipynb#Y104sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m Results,sim \u001b[39m=\u001b[39m Top_n(Q1, fast_n,fast_text_vectors,data1)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/97158/Desktop/Apziva/Project%203-%20Potential%20Talents/Potential%20Talents.ipynb#Y104sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m Results,sim\n",
      "\u001b[1;32mc:\\Users\\97158\\Desktop\\Apziva\\Project 3- Potential Talents\\Potential Talents.ipynb Cell 55\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/97158/Desktop/Apziva/Project%203-%20Potential%20Talents/Potential%20Talents.ipynb#Y104sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m temp \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/97158/Desktop/Apziva/Project%203-%20Potential%20Talents/Potential%20Talents.ipynb#Y104sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m#Sorting the list\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/97158/Desktop/Apziva/Project%203-%20Potential%20Talents/Potential%20Talents.ipynb#Y104sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m sort\u001b[39m=\u001b[39mtemp\u001b[39m.\u001b[39msort(reverse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)[:\u001b[39m10\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/97158/Desktop/Apziva/Project%203-%20Potential%20Talents/Potential%20Talents.ipynb#Y104sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m sim\u001b[39m=\u001b[39m[temp[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mreversed\u001b[39m(sort)]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/97158/Desktop/Apziva/Project%203-%20Potential%20Talents/Potential%20Talents.ipynb#Y104sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mprint\u001b[39m(sim)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "Q1= \"Aspiring human resources\"\n",
    "\n",
    "Results,sim = Top_n(Q1, fast_n,fast_text_vectors,data1)\n",
    "Results,sim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104, 100)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_text_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
